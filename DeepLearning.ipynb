{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnQIyucj-0sY"
      },
      "source": [
        "#Importing required libraries.\r\n",
        "\r\n",
        "from keras import backend as K\r\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\r\n",
        "from keras.models import Sequential, Model\r\n",
        "from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D,Convolution2D\r\n",
        "from keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\r\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\r\n",
        "from keras.optimizers import Adam, SGD, RMSprop\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX9DkMGl5AQ1"
      },
      "source": [
        "# **Importing dataset from google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFONGOKc15Q6",
        "outputId": "e3c16d39-cf6c-43f3-973f-a9a9338a0fbe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8Heb_SZ5ORE"
      },
      "source": [
        "# **Connecting Data from Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EFN4RNYTiGd"
      },
      "source": [
        "data_location = '/content/drive/MyDrive/DeepLearningPorject/data_set/check/Khela/train/covid'\r\n",
        "CLASS_NAMES = ['covid-19', 'healthy'] \r\n",
        "IMAGE_SHAPE = (256, 256, 3)\r\n",
        "BATCH_SIZE = 10\r\n",
        "EPOCHS = 50\r\n",
        "DATASET_SIZE = sum([len(files) for r, d, files in os.walk(data_location)])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6jpGDueUMbx",
        "outputId": "6424b6ca-2e7f-4b93-fde6-e8ea227df998"
      },
      "source": [
        "DATASET_SIZE  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "242"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mocZyWJ5liV"
      },
      "source": [
        "#We had very few covid-positive datas. So we did data augmentation to create new covid-positive datas by changong some attributes from existing datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbuD7Me1gjhX"
      },
      "source": [
        "import keras\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import glob\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\n",
        "datagen = ImageDataGenerator(rotation_range =5,    \r\n",
        "                         rescale=1./255, \r\n",
        "                         shear_range=0.2, \r\n",
        "                         zoom_range=0.3, \r\n",
        "                         horizontal_flip = True, \r\n",
        "                         fill_mode = 'nearest', \r\n",
        "                         data_format='channels_last', \r\n",
        "                         brightness_range=[0.2,1.0])\r\n",
        "\r\n",
        "\r\n",
        "img_dir = \"/content/drive/MyDrive/DeepLearningPorject/data_set/check/Khela/train/covid\" # Enter Directory of all images \r\n",
        "data_path = os.path.join(img_dir,'*g')\r\n",
        "files = glob.glob(data_path)\r\n",
        "data = []\r\n",
        "for f1 in files:\r\n",
        "    img = cv2.imread(f1)\r\n",
        "    data.append(img)\r\n",
        "\r\n",
        "x = img_to_array(img)\r\n",
        "x = x.reshape((1,) + x.shape)\r\n",
        "\r\n",
        "i = 0\r\n",
        "path, dirs, files = next(os.walk(\"/content/drive/MyDrive/DeepLearningPorject/data_set/check/Khela/train/covid\"))\r\n",
        "file_count = len(files) #to find number of files in folder\r\n",
        "\r\n",
        "for batch in datagen.flow (x, batch_size=1, save_to_dir =r'/content/drive/MyDrive/DeepLearningPorject/data_set/check/Khela/train/covid',save_prefix=\"a\",save_format='jpg'):\r\n",
        "    i+=1\r\n",
        "    if i==file_count:\r\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12fex4NaHvGZ"
      },
      "source": [
        "# **For deleting extra folder of Augmented images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptr4GPtzkDk9"
      },
      "source": [
        "# import os\r\n",
        "\r\n",
        "# filelist = [ f for f in os.listdir(\"/content/drive/MyDrive/DeepLearningPorject/data_set/train/new\") if f.endswith(\".jpg\") ]\r\n",
        "# for f in filelist:\r\n",
        "#     os.remove(os.path.join(\"/content/drive/MyDrive/DeepLearningPorject/data_set/train/new\", f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxR_vY0hUOMU",
        "outputId": "b42d2c23-d139-4aa8-e511-f24f33fa4d1c"
      },
      "source": [
        "#Fitting to CNN to the images\r\n",
        "\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "        rescale=1./255,\r\n",
        "        shear_range=0.2,\r\n",
        "        zoom_range=0.2,\r\n",
        "        rotation_range=40,\r\n",
        "        brightness_range=[0.2,1.0],\r\n",
        "        width_shift_range=0.2,\r\n",
        "        height_shift_range=0.2,\r\n",
        "        horizontal_flip=True,\r\n",
        "        fill_mode = 'nearest')\r\n",
        "\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "\r\n",
        "training_set = train_datagen.flow_from_directory(\r\n",
        "        '/content/drive/MyDrive/DeepLearningPorject/data_set/check/Khela/train',\r\n",
        "        target_size=(64, 64),\r\n",
        "        batch_size=32,\r\n",
        "        class_mode='binary')\r\n",
        "\r\n",
        "test_set = test_datagen.flow_from_directory(\r\n",
        "        '/content/drive/MyDrive/DeepLearningPorject/data_set/check/Khela/test',\r\n",
        "        target_size=(64, 64),\r\n",
        "        batch_size=32,\r\n",
        "        class_mode='binary')\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1236 images belonging to 2 classes.\n",
            "Found 1573 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMspybWkImae"
      },
      "source": [
        "# **Initializing the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il0t2Jn8UwYr"
      },
      "source": [
        "classifier = Sequential()\r\n",
        "\r\n",
        "#step 1 - Convolution\r\n",
        "#creating the feature map by using feature detector from Ä±nput image\r\n",
        "\r\n",
        "classifier.add( Convolution2D(32,3,3, input_shape=(64,64,3), activation='relu'))\r\n",
        "#32 Feature maps&detetctors uses 3 by 3 matrices, we can put 128 in the powerful machines\r\n",
        "\r\n",
        "\r\n",
        "#step -2 Pooling\r\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\r\n",
        "# classifier.add(Dropout(0.25))\r\n",
        "\r\n",
        "#second convolution and pooling steps.\r\n",
        "classifier.add( Convolution2D(32,3,3,input_shape=(64,64,3), activation='relu'))\r\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\r\n",
        "# classifier.add(Dropout(0.25))\r\n",
        "\r\n",
        "\r\n",
        "#step -3 Flattening\r\n",
        "classifier.add(Flatten())\r\n",
        "\r\n",
        "#step-4 Full connection step\r\n",
        "classifier.add(Dense(256, activation = 'relu'))\r\n",
        "classifier.add(Dense(1, activation = 'sigmoid'))\r\n",
        "#binary outcome"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6HG9MFQIvYC"
      },
      "source": [
        "# **Compiling the Moedel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMj75hBrWGJu"
      },
      "source": [
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBxxSmD_Jpvo"
      },
      "source": [
        "# **Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPJyt5nVU7cn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bead75e-180b-4919-cdc3-7013057bec27"
      },
      "source": [
        "steps_per_epoch = len(training_set)//BATCH_SIZE\r\n",
        "validation_steps = len(test_set)//BATCH_SIZE # if you have test data\r\n",
        "\r\n",
        "\r\n",
        "results = classifier.fit(training_set,\r\n",
        "                    steps_per_epoch=steps_per_epoch,\r\n",
        "                    epochs=100,\r\n",
        "                    validation_data=test_set,\r\n",
        "                    validation_steps=validation_steps,\r\n",
        "                    workers=1)\r\n",
        "print(len(training_set))\r\n",
        "print(len(test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 107s 45s/step - loss: 0.6771 - accuracy: 0.6992 - val_loss: 0.5347 - val_accuracy: 0.9312\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.8160 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ZIQ2ZIJt27"
      },
      "source": [
        "# **Model summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hWeI7OzlTDu"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEekWsCEJx5h"
      },
      "source": [
        "# **Training VS Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdvUr3VKiIEc"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "def plot_acc_loss(results, epochs):\r\n",
        " acc = results.history['accuracy']\r\n",
        " loss = results.history['loss']\r\n",
        " val_acc = results.history['val_accuracy']\r\n",
        " val_loss = results.history['val_loss']\r\n",
        " plt.figure(figsize=(25, 10))\r\n",
        " plt.subplot(121)\r\n",
        " plt.plot(range(1,epochs), acc[1:], label='Train_acc')\r\n",
        " plt.plot(range(1,epochs), val_acc[1:], label='Test_acc')\r\n",
        " plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\r\n",
        " plt.legend()\r\n",
        " plt.grid(True)\r\n",
        " plt.subplot(122)\r\n",
        " plt.plot(range(1,epochs), loss[1:], label='Train_loss')\r\n",
        " plt.plot(range(1,epochs), val_loss[1:], label='Test_loss')\r\n",
        " plt.title('Loss over ' + str(epochs) +  ' Epochs', size=15)\r\n",
        " plt.legend()\r\n",
        " plt.grid(True)\r\n",
        " plt.show()\r\n",
        " \r\n",
        "plot_acc_loss(results, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46VUpdBbJ4pU"
      },
      "source": [
        "# **Making new predictions**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yijmMDhWby0R"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.preprocessing import image\r\n",
        "\r\n",
        "#First learn the classification indices.\r\n",
        "print(training_set.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWB80pchTBke"
      },
      "source": [
        "\r\n",
        "%pylab inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "\r\n",
        "# Test Image\r\n",
        "\r\n",
        "imagePath = \"/content/drive/MyDrive/DeepLearningPorject/data_set/check/Khela/test/covid/16660_1_1.jpg\"\r\n",
        "\r\n",
        "img=mpimg.imread(imagePath)\r\n",
        "imgplot = plt.imshow(img)\r\n",
        "\r\n",
        "test_image = image.load_img(imagePath, target_size = (64, 64))\r\n",
        "test_image = image.img_to_array(test_image)\r\n",
        "test_image = np.expand_dims(test_image, axis = 0)\r\n",
        "result = classifier.predict(test_image)\r\n",
        "\r\n",
        "result\r\n",
        "\r\n",
        "if result[0][0] == 1:\r\n",
        "    prediction = 'normal'\r\n",
        "else:\r\n",
        "    prediction = 'covid'\r\n",
        "\r\n",
        "    \r\n",
        "# print(\"AI's prediction is: \"+ prediction)\r\n",
        "\r\n",
        "plt=plt.title('Prediction is  '+ prediction )\r\n",
        "#There we will test this following image, COVID-19 positive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZcPDVy74NMs"
      },
      "source": [
        "loss, accuracy = classifier.evaluate(test_set, steps = validation_steps)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(\"Loss: {:.2f}\".format(loss))\r\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy))\r\n",
        "print(\"---------------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXqzxiQgxcDB"
      },
      "source": [
        "\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}